{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Student-Info\" data-toc-modified-id=\"Student-Info-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Student Info</a></span></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Step-1:-Load-the-Data/Filtering-for-Chosen-Zipcodes\" data-toc-modified-id=\"Step-1:-Load-the-Data/Filtering-for-Chosen-Zipcodes-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Step 1: Load the Data/Filtering for Chosen Zipcodes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-Null-Values\" data-toc-modified-id=\"Check-Null-Values-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Check Null Values</a></span></li><li><span><a href=\"#Examine-Data-Types\" data-toc-modified-id=\"Examine-Data-Types-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Examine Data Types</a></span></li><li><span><a href=\"#Check-for-Outliers\" data-toc-modified-id=\"Check-for-Outliers-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Check for Outliers</a></span></li><li><span><a href=\"#Check-for-Unique-Values\" data-toc-modified-id=\"Check-for-Unique-Values-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Check for Unique Values</a></span></li></ul></li><li><span><a href=\"#Step-2:-Data-Preprocessing\" data-toc-modified-id=\"Step-2:-Data-Preprocessing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Step 2: Data Preprocessing</a></span></li><li><span><a href=\"#Step-3:-EDA-and-Visualization\" data-toc-modified-id=\"Step-3:-EDA-and-Visualization-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Step 3: EDA and Visualization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Difference-time-series\" data-toc-modified-id=\"Difference-time-series-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Difference time series</a></span></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Correlations</a></span></li><li><span><a href=\"#Seasonal-Decomposition\" data-toc-modified-id=\"Seasonal-Decomposition-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Seasonal Decomposition</a></span></li></ul></li><li><span><a href=\"#Step-5:-ARIMA-Modeling\" data-toc-modified-id=\"Step-5:-ARIMA-Modeling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Step 5: ARIMA Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Parameter-Selection-for-the-ARIMA-Time-Series-Model\" data-toc-modified-id=\"Parameter-Selection-for-the-ARIMA-Time-Series-Model-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Parameter Selection for the ARIMA Time Series Model</a></span></li><li><span><a href=\"#AIC-(Akaike-Information-Criterion)-as-Regularization-Measure\" data-toc-modified-id=\"AIC-(Akaike-Information-Criterion)-as-Regularization-Measure-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>AIC (Akaike Information Criterion) as Regularization Measure</a></span></li></ul></li><li><span><a href=\"#Validating-the-Model\" data-toc-modified-id=\"Validating-the-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Validating the Model</a></span></li><li><span><a href=\"#Step-6:-Interpreting-Results\" data-toc-modified-id=\"Step-6:-Interpreting-Results-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Step 6: Interpreting Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plot-Real-Vs-Predicted\" data-toc-modified-id=\"Plot-Real-Vs-Predicted-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Plot Real Vs Predicted</a></span></li><li><span><a href=\"#Dynamic-Forecasting\" data-toc-modified-id=\"Dynamic-Forecasting-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Dynamic Forecasting</a></span></li><li><span><a href=\"#Producing-and-Visualizing-Forecasts\" data-toc-modified-id=\"Producing-and-Visualizing-Forecasts-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Producing and Visualizing Forecasts</a></span></li><li><span><a href=\"#Final-Analysis\" data-toc-modified-id=\"Final-Analysis-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Final Analysis</a></span></li><li><span><a href=\"#Recommendations\" data-toc-modified-id=\"Recommendations-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>Recommendations</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Info\n",
    "Name: Susanna Mir\n",
    "Cohort: DS-PT\n",
    "Instructor: James Irving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    ">The main goal of this project \n",
    "\n",
    ">The data analysed \n",
    "\n",
    ">The target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the Data/Filtering for Chosen Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import warnings\n",
    "#warnings.filter.options(‘ignore’)\n",
    "#plt.style.use(‘seaborn-poster')\n",
    "#import functions_mod4_proj as  fc_mod4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('zillow_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>235700.0</td>\n",
       "      <td>236900.0</td>\n",
       "      <td>236700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>210400.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  RegionName      City State              Metro CountyName  \\\n",
       "0     84654       60657   Chicago    IL            Chicago       Cook   \n",
       "1     90668       75070  McKinney    TX  Dallas-Fort Worth     Collin   \n",
       "2     91982       77494      Katy    TX            Houston     Harris   \n",
       "3     84616       60614   Chicago    IL            Chicago       Cook   \n",
       "4     93144       79936   El Paso    TX            El Paso    El Paso   \n",
       "\n",
       "   SizeRank   1996-04   1996-05   1996-06   ...     2017-07  2017-08  2017-09  \\\n",
       "0         1  334200.0  335400.0  336500.0   ...     1005500  1007500  1007800   \n",
       "1         2  235700.0  236900.0  236700.0   ...      308000   310000   312500   \n",
       "2         3  210400.0  212200.0  212200.0   ...      321000   320600   320200   \n",
       "3         4  498100.0  500900.0  503100.0   ...     1289800  1287700  1287400   \n",
       "4         5   77300.0   77300.0   77300.0   ...      119100   119400   120000   \n",
       "\n",
       "   2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  2018-04  \n",
       "0  1009600  1013300  1018700  1024400  1030700  1033800  1030600  \n",
       "1   314100   315000   316600   318100   319600   321100   321800  \n",
       "2   320400   320800   321200   321200   323000   326900   329900  \n",
       "3  1291500  1296600  1299000  1302700  1306400  1308500  1307000  \n",
       "4   120300   120300   120300   120300   120500   121000   121500  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Clean check - are there any null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metro      1043\n",
       "1996-04    1039\n",
       "1996-05    1039\n",
       "1996-06    1039\n",
       "1996-07    1039\n",
       "1996-08    1039\n",
       "1996-09    1039\n",
       "1996-10    1039\n",
       "1996-11    1039\n",
       "1996-12    1039\n",
       "1997-01    1039\n",
       "1997-02    1039\n",
       "1997-03    1039\n",
       "1997-04    1039\n",
       "1997-05    1039\n",
       "1997-06    1039\n",
       "1997-07    1038\n",
       "1997-08    1038\n",
       "1997-09    1038\n",
       "1997-10    1038\n",
       "1997-11    1038\n",
       "1997-12    1038\n",
       "1998-01    1036\n",
       "1998-02    1036\n",
       "1998-03    1036\n",
       "1998-04    1036\n",
       "1998-05    1036\n",
       "1998-06    1036\n",
       "1998-07    1036\n",
       "1998-08    1036\n",
       "           ... \n",
       "2012-01     224\n",
       "2012-02     224\n",
       "2012-03     224\n",
       "2012-04     224\n",
       "2012-05     224\n",
       "2012-06     224\n",
       "2012-07     206\n",
       "2012-08     206\n",
       "2012-09     206\n",
       "2012-10     206\n",
       "2012-11     206\n",
       "2012-12     206\n",
       "2013-01     151\n",
       "2013-02     151\n",
       "2013-03     151\n",
       "2013-04     151\n",
       "2013-05     151\n",
       "2013-06     151\n",
       "2013-07     109\n",
       "2013-08     109\n",
       "2013-09     109\n",
       "2013-10     109\n",
       "2013-11     109\n",
       "2013-12     109\n",
       "2014-01      56\n",
       "2014-02      56\n",
       "2014-03      56\n",
       "2014-04      56\n",
       "2014-05      56\n",
       "2014-06      56\n",
       "Length: 220, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = data.isna().sum()\n",
    "nulls[nulls >0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs.quick_refs.ts_pandas_freq_aliases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_datetime_index(df, col_to_make_index='Month', drop=False, verbose=True):\n",
    "    \n",
    "#         col_to_make_index = 'Month'\n",
    "#         df[col_to_make_index] = pd.to_datetime(df[col_to_make_index].errors='coerce')\n",
    "#         df=df.set_index('Month',drop=false)\n",
    "#         df.index\n",
    "\n",
    "#         if verbose:\n",
    "#             display(df.index)\n",
    "#         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = data.groupby('RegionName').resample('MS')\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionID        int64\n",
       "RegionName      int64\n",
       "City           object\n",
       "State          object\n",
       "Metro          object\n",
       "CountyName     object\n",
       "SizeRank        int64\n",
       "1996-04       float64\n",
       "1996-05       float64\n",
       "1996-06       float64\n",
       "1996-07       float64\n",
       "1996-08       float64\n",
       "1996-09       float64\n",
       "1996-10       float64\n",
       "1996-11       float64\n",
       "1996-12       float64\n",
       "1997-01       float64\n",
       "1997-02       float64\n",
       "1997-03       float64\n",
       "1997-04       float64\n",
       "1997-05       float64\n",
       "1997-06       float64\n",
       "1997-07       float64\n",
       "1997-08       float64\n",
       "1997-09       float64\n",
       "1997-10       float64\n",
       "1997-11       float64\n",
       "1997-12       float64\n",
       "1998-01       float64\n",
       "1998-02       float64\n",
       "               ...   \n",
       "2015-11         int64\n",
       "2015-12         int64\n",
       "2016-01         int64\n",
       "2016-02         int64\n",
       "2016-03         int64\n",
       "2016-04         int64\n",
       "2016-05         int64\n",
       "2016-06         int64\n",
       "2016-07         int64\n",
       "2016-08         int64\n",
       "2016-09         int64\n",
       "2016-10         int64\n",
       "2016-11         int64\n",
       "2016-12         int64\n",
       "2017-01         int64\n",
       "2017-02         int64\n",
       "2017-03         int64\n",
       "2017-04         int64\n",
       "2017-05         int64\n",
       "2017-06         int64\n",
       "2017-07         int64\n",
       "2017-08         int64\n",
       "2017-09         int64\n",
       "2017-10         int64\n",
       "2017-11         int64\n",
       "2017-12         int64\n",
       "2018-01         int64\n",
       "2018-02         int64\n",
       "2018-03         int64\n",
       "2018-04         int64\n",
       "Length: 272, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>1996-07</th>\n",
       "      <th>1996-08</th>\n",
       "      <th>1996-09</th>\n",
       "      <th>1996-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14723.000000</td>\n",
       "      <td>14723.000000</td>\n",
       "      <td>14723.000000</td>\n",
       "      <td>1.368400e+04</td>\n",
       "      <td>1.368400e+04</td>\n",
       "      <td>1.368400e+04</td>\n",
       "      <td>1.368400e+04</td>\n",
       "      <td>1.368400e+04</td>\n",
       "      <td>1.368400e+04</td>\n",
       "      <td>1.368400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "      <td>1.472300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81075.010052</td>\n",
       "      <td>48222.348706</td>\n",
       "      <td>7362.000000</td>\n",
       "      <td>1.182991e+05</td>\n",
       "      <td>1.184190e+05</td>\n",
       "      <td>1.185374e+05</td>\n",
       "      <td>1.186531e+05</td>\n",
       "      <td>1.187803e+05</td>\n",
       "      <td>1.189275e+05</td>\n",
       "      <td>1.191205e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.733354e+05</td>\n",
       "      <td>2.748658e+05</td>\n",
       "      <td>2.764646e+05</td>\n",
       "      <td>2.780332e+05</td>\n",
       "      <td>2.795209e+05</td>\n",
       "      <td>2.810953e+05</td>\n",
       "      <td>2.826571e+05</td>\n",
       "      <td>2.843687e+05</td>\n",
       "      <td>2.865114e+05</td>\n",
       "      <td>2.880399e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31934.118525</td>\n",
       "      <td>29359.325439</td>\n",
       "      <td>4250.308342</td>\n",
       "      <td>8.600251e+04</td>\n",
       "      <td>8.615567e+04</td>\n",
       "      <td>8.630923e+04</td>\n",
       "      <td>8.646795e+04</td>\n",
       "      <td>8.665094e+04</td>\n",
       "      <td>8.687208e+04</td>\n",
       "      <td>8.715185e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.603984e+05</td>\n",
       "      <td>3.614678e+05</td>\n",
       "      <td>3.627563e+05</td>\n",
       "      <td>3.644610e+05</td>\n",
       "      <td>3.656003e+05</td>\n",
       "      <td>3.670454e+05</td>\n",
       "      <td>3.695727e+05</td>\n",
       "      <td>3.717739e+05</td>\n",
       "      <td>3.724612e+05</td>\n",
       "      <td>3.720544e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>58196.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.130000e+04</td>\n",
       "      <td>1.150000e+04</td>\n",
       "      <td>1.160000e+04</td>\n",
       "      <td>1.180000e+04</td>\n",
       "      <td>1.180000e+04</td>\n",
       "      <td>1.200000e+04</td>\n",
       "      <td>1.210000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.440000e+04</td>\n",
       "      <td>1.450000e+04</td>\n",
       "      <td>1.470000e+04</td>\n",
       "      <td>1.480000e+04</td>\n",
       "      <td>1.450000e+04</td>\n",
       "      <td>1.430000e+04</td>\n",
       "      <td>1.410000e+04</td>\n",
       "      <td>1.390000e+04</td>\n",
       "      <td>1.380000e+04</td>\n",
       "      <td>1.380000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67174.500000</td>\n",
       "      <td>22101.500000</td>\n",
       "      <td>3681.500000</td>\n",
       "      <td>6.880000e+04</td>\n",
       "      <td>6.890000e+04</td>\n",
       "      <td>6.910000e+04</td>\n",
       "      <td>6.920000e+04</td>\n",
       "      <td>6.937500e+04</td>\n",
       "      <td>6.950000e+04</td>\n",
       "      <td>6.960000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.269000e+05</td>\n",
       "      <td>1.275000e+05</td>\n",
       "      <td>1.282000e+05</td>\n",
       "      <td>1.287000e+05</td>\n",
       "      <td>1.292500e+05</td>\n",
       "      <td>1.299000e+05</td>\n",
       "      <td>1.306000e+05</td>\n",
       "      <td>1.310500e+05</td>\n",
       "      <td>1.319500e+05</td>\n",
       "      <td>1.324000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78007.000000</td>\n",
       "      <td>46106.000000</td>\n",
       "      <td>7362.000000</td>\n",
       "      <td>9.950000e+04</td>\n",
       "      <td>9.950000e+04</td>\n",
       "      <td>9.970000e+04</td>\n",
       "      <td>9.970000e+04</td>\n",
       "      <td>9.980000e+04</td>\n",
       "      <td>9.990000e+04</td>\n",
       "      <td>9.995000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.884000e+05</td>\n",
       "      <td>1.896000e+05</td>\n",
       "      <td>1.905000e+05</td>\n",
       "      <td>1.914000e+05</td>\n",
       "      <td>1.925000e+05</td>\n",
       "      <td>1.934000e+05</td>\n",
       "      <td>1.941000e+05</td>\n",
       "      <td>1.950000e+05</td>\n",
       "      <td>1.967000e+05</td>\n",
       "      <td>1.981000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90920.500000</td>\n",
       "      <td>75205.500000</td>\n",
       "      <td>11042.500000</td>\n",
       "      <td>1.432000e+05</td>\n",
       "      <td>1.433000e+05</td>\n",
       "      <td>1.432250e+05</td>\n",
       "      <td>1.432250e+05</td>\n",
       "      <td>1.435000e+05</td>\n",
       "      <td>1.437000e+05</td>\n",
       "      <td>1.439000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.050000e+05</td>\n",
       "      <td>3.066500e+05</td>\n",
       "      <td>3.085000e+05</td>\n",
       "      <td>3.098000e+05</td>\n",
       "      <td>3.117000e+05</td>\n",
       "      <td>3.134000e+05</td>\n",
       "      <td>3.151000e+05</td>\n",
       "      <td>3.168500e+05</td>\n",
       "      <td>3.188500e+05</td>\n",
       "      <td>3.211000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>753844.000000</td>\n",
       "      <td>99901.000000</td>\n",
       "      <td>14723.000000</td>\n",
       "      <td>3.676700e+06</td>\n",
       "      <td>3.704200e+06</td>\n",
       "      <td>3.729600e+06</td>\n",
       "      <td>3.754600e+06</td>\n",
       "      <td>3.781800e+06</td>\n",
       "      <td>3.813500e+06</td>\n",
       "      <td>3.849600e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.888990e+07</td>\n",
       "      <td>1.870350e+07</td>\n",
       "      <td>1.860530e+07</td>\n",
       "      <td>1.856940e+07</td>\n",
       "      <td>1.842880e+07</td>\n",
       "      <td>1.830710e+07</td>\n",
       "      <td>1.836590e+07</td>\n",
       "      <td>1.853040e+07</td>\n",
       "      <td>1.833770e+07</td>\n",
       "      <td>1.789490e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RegionID    RegionName      SizeRank       1996-04       1996-05  \\\n",
       "count   14723.000000  14723.000000  14723.000000  1.368400e+04  1.368400e+04   \n",
       "mean    81075.010052  48222.348706   7362.000000  1.182991e+05  1.184190e+05   \n",
       "std     31934.118525  29359.325439   4250.308342  8.600251e+04  8.615567e+04   \n",
       "min     58196.000000   1001.000000      1.000000  1.130000e+04  1.150000e+04   \n",
       "25%     67174.500000  22101.500000   3681.500000  6.880000e+04  6.890000e+04   \n",
       "50%     78007.000000  46106.000000   7362.000000  9.950000e+04  9.950000e+04   \n",
       "75%     90920.500000  75205.500000  11042.500000  1.432000e+05  1.433000e+05   \n",
       "max    753844.000000  99901.000000  14723.000000  3.676700e+06  3.704200e+06   \n",
       "\n",
       "            1996-06       1996-07       1996-08       1996-09       1996-10  \\\n",
       "count  1.368400e+04  1.368400e+04  1.368400e+04  1.368400e+04  1.368400e+04   \n",
       "mean   1.185374e+05  1.186531e+05  1.187803e+05  1.189275e+05  1.191205e+05   \n",
       "std    8.630923e+04  8.646795e+04  8.665094e+04  8.687208e+04  8.715185e+04   \n",
       "min    1.160000e+04  1.180000e+04  1.180000e+04  1.200000e+04  1.210000e+04   \n",
       "25%    6.910000e+04  6.920000e+04  6.937500e+04  6.950000e+04  6.960000e+04   \n",
       "50%    9.970000e+04  9.970000e+04  9.980000e+04  9.990000e+04  9.995000e+04   \n",
       "75%    1.432250e+05  1.432250e+05  1.435000e+05  1.437000e+05  1.439000e+05   \n",
       "max    3.729600e+06  3.754600e+06  3.781800e+06  3.813500e+06  3.849600e+06   \n",
       "\n",
       "           ...            2017-07       2017-08       2017-09       2017-10  \\\n",
       "count      ...       1.472300e+04  1.472300e+04  1.472300e+04  1.472300e+04   \n",
       "mean       ...       2.733354e+05  2.748658e+05  2.764646e+05  2.780332e+05   \n",
       "std        ...       3.603984e+05  3.614678e+05  3.627563e+05  3.644610e+05   \n",
       "min        ...       1.440000e+04  1.450000e+04  1.470000e+04  1.480000e+04   \n",
       "25%        ...       1.269000e+05  1.275000e+05  1.282000e+05  1.287000e+05   \n",
       "50%        ...       1.884000e+05  1.896000e+05  1.905000e+05  1.914000e+05   \n",
       "75%        ...       3.050000e+05  3.066500e+05  3.085000e+05  3.098000e+05   \n",
       "max        ...       1.888990e+07  1.870350e+07  1.860530e+07  1.856940e+07   \n",
       "\n",
       "            2017-11       2017-12       2018-01       2018-02       2018-03  \\\n",
       "count  1.472300e+04  1.472300e+04  1.472300e+04  1.472300e+04  1.472300e+04   \n",
       "mean   2.795209e+05  2.810953e+05  2.826571e+05  2.843687e+05  2.865114e+05   \n",
       "std    3.656003e+05  3.670454e+05  3.695727e+05  3.717739e+05  3.724612e+05   \n",
       "min    1.450000e+04  1.430000e+04  1.410000e+04  1.390000e+04  1.380000e+04   \n",
       "25%    1.292500e+05  1.299000e+05  1.306000e+05  1.310500e+05  1.319500e+05   \n",
       "50%    1.925000e+05  1.934000e+05  1.941000e+05  1.950000e+05  1.967000e+05   \n",
       "75%    3.117000e+05  3.134000e+05  3.151000e+05  3.168500e+05  3.188500e+05   \n",
       "max    1.842880e+07  1.830710e+07  1.836590e+07  1.853040e+07  1.833770e+07   \n",
       "\n",
       "            2018-04  \n",
       "count  1.472300e+04  \n",
       "mean   2.880399e+05  \n",
       "std    3.720544e+05  \n",
       "min    1.380000e+04  \n",
       "25%    1.324000e+05  \n",
       "50%    1.981000e+05  \n",
       "75%    3.211000e+05  \n",
       "max    1.789490e+07  \n",
       "\n",
       "[8 rows x 268 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14723, 272)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a box plot of each column and check for significant outliers\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.boxplot([data[col] for col in data.columns])\n",
    "# plt.title(\"Box plot of all columns in dataset\")\n",
    "# plt.xticks(range(len(data.columns.values)), data.columns.values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionID      12895\n",
       "RegionName    12895\n",
       "City           6591\n",
       "State            50\n",
       "Metro           642\n",
       "CountyName      917\n",
       "SizeRank      12895\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many unique values we have on each column, besides date/time data\n",
    "data.iloc[:,0:7].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>235700.0</td>\n",
       "      <td>236900.0</td>\n",
       "      <td>236700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>210400.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  Zipcode      City State              Metro CountyName  SizeRank  \\\n",
       "0     84654    60657   Chicago    IL            Chicago       Cook         1   \n",
       "1     90668    75070  McKinney    TX  Dallas-Fort Worth     Collin         2   \n",
       "2     91982    77494      Katy    TX            Houston     Harris         3   \n",
       "3     84616    60614   Chicago    IL            Chicago       Cook         4   \n",
       "4     93144    79936   El Paso    TX            El Paso    El Paso         5   \n",
       "\n",
       "    1996-04   1996-05   1996-06   ...     2017-07  2017-08  2017-09  2017-10  \\\n",
       "0  334200.0  335400.0  336500.0   ...     1005500  1007500  1007800  1009600   \n",
       "1  235700.0  236900.0  236700.0   ...      308000   310000   312500   314100   \n",
       "2  210400.0  212200.0  212200.0   ...      321000   320600   320200   320400   \n",
       "3  498100.0  500900.0  503100.0   ...     1289800  1287700  1287400  1291500   \n",
       "4   77300.0   77300.0   77300.0   ...      119100   119400   120000   120300   \n",
       "\n",
       "   2017-11  2017-12  2018-01  2018-02  2018-03  2018-04  \n",
       "0  1013300  1018700  1024400  1030700  1033800  1030600  \n",
       "1   315000   316600   318100   319600   321100   321800  \n",
       "2   320800   321200   321200   323000   326900   329900  \n",
       "3  1296600  1299000  1302700  1306400  1308500  1307000  \n",
       "4   120300   120300   120300   120500   121000   121500  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename column that refers to zipcodes\n",
    "data.rename({'RegionName': 'Zipcode'}, axis='columns', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chicago = data.loc[data['City'] == 'Chicago'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84640</td>\n",
       "      <td>60640</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>8</td>\n",
       "      <td>216500.0</td>\n",
       "      <td>216700.0</td>\n",
       "      <td>216900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>798000</td>\n",
       "      <td>787100</td>\n",
       "      <td>776100</td>\n",
       "      <td>774900</td>\n",
       "      <td>777900</td>\n",
       "      <td>777900</td>\n",
       "      <td>778500</td>\n",
       "      <td>780500</td>\n",
       "      <td>782800</td>\n",
       "      <td>782800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>84646</td>\n",
       "      <td>60647</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>17</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>122800.0</td>\n",
       "      <td>122800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>459600</td>\n",
       "      <td>461400</td>\n",
       "      <td>464300</td>\n",
       "      <td>466500</td>\n",
       "      <td>467900</td>\n",
       "      <td>470600</td>\n",
       "      <td>474500</td>\n",
       "      <td>475100</td>\n",
       "      <td>472600</td>\n",
       "      <td>470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>84620</td>\n",
       "      <td>60618</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>20</td>\n",
       "      <td>142600.0</td>\n",
       "      <td>143100.0</td>\n",
       "      <td>143400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>462700</td>\n",
       "      <td>461200</td>\n",
       "      <td>459900</td>\n",
       "      <td>459200</td>\n",
       "      <td>458700</td>\n",
       "      <td>457900</td>\n",
       "      <td>457400</td>\n",
       "      <td>459000</td>\n",
       "      <td>462500</td>\n",
       "      <td>464300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RegionID  Zipcode     City State    Metro CountyName  SizeRank   1996-04  \\\n",
       "0      84654    60657  Chicago    IL  Chicago       Cook         1  334200.0   \n",
       "3      84616    60614  Chicago    IL  Chicago       Cook         4  498100.0   \n",
       "7      84640    60640  Chicago    IL  Chicago       Cook         8  216500.0   \n",
       "16     84646    60647  Chicago    IL  Chicago       Cook        17  122700.0   \n",
       "19     84620    60618  Chicago    IL  Chicago       Cook        20  142600.0   \n",
       "\n",
       "     1996-05   1996-06   ...     2017-07  2017-08  2017-09  2017-10  2017-11  \\\n",
       "0   335400.0  336500.0   ...     1005500  1007500  1007800  1009600  1013300   \n",
       "3   500900.0  503100.0   ...     1289800  1287700  1287400  1291500  1296600   \n",
       "7   216700.0  216900.0   ...      798000   787100   776100   774900   777900   \n",
       "16  122800.0  122800.0   ...      459600   461400   464300   466500   467900   \n",
       "19  143100.0  143400.0   ...      462700   461200   459900   459200   458700   \n",
       "\n",
       "    2017-12  2018-01  2018-02  2018-03  2018-04  \n",
       "0   1018700  1024400  1030700  1033800  1030600  \n",
       "3   1299000  1302700  1306400  1308500  1307000  \n",
       "7    777900   778500   780500   782800   782800  \n",
       "16   470600   474500   475100   472600   470200  \n",
       "19   457900   457400   459000   462500   464300  \n",
       "\n",
       "[5 rows x 272 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chicago.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt data and make it into time series\n",
    "\n",
    "def melt_data(df):\n",
    "    ''' \n",
    "    Takes a dataframe with datetime data that is in wide format and melts it into long format; \n",
    "    Transforms data into datetime object with time as index.\n",
    "                    df          Dataframe to transform\n",
    "    '''\n",
    "    \n",
    "    melted = pd.melt(df, id_vars=['RegionID', 'Zipcode', 'City', 'State', 'Metro', 'CountyName', 'SizeRank'], var_name='time')\n",
    "    melted['time'] = pd.to_datetime(melted['time'], infer_datetime_format=True)\n",
    "    melted = melted.dropna(subset=['value'])\n",
    "    return melted\n",
    "    #return melted.groupby('time').aggregate({'value':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Zipcode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Zipcode'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8a3472453f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# apply function to our data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmelted_df_chicago\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelt_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_chicago\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-080f7bd1afb7>\u001b[0m in \u001b[0;36mmelt_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      8\u001b[0m     '''\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmelted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RegionID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Zipcode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'City'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'State'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Metro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CountyName'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SizeRank'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmelted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmelted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/reshape/melt.py\u001b[0m in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mmdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \"\"\"\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Zipcode'"
     ]
    }
   ],
   "source": [
    "# apply function to our data:\n",
    "melted_df_chicago = melt_data(df_chicago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df_chicago.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: EDA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Ts = df2[‘MeanValue’].loc[21207]\n",
    "# #********************************************\n",
    "# def plot_ts(df2, col='MeanValue', zipcodes=[21201]):\n",
    "#     '''' \n",
    "#     Takes a dataframe with datetime data that is in wide format and melts it into long format; \n",
    "#     Tranforms data into datetime object with time as index.\n",
    "#                     df          Dataframe to transform\n",
    "#     '''\n",
    "\n",
    "#     ax = ts.plot(label='Raw Price')\n",
    "#     fig, ax = plt.subplots()\n",
    "\n",
    "#     for zc in zipcodes:\n",
    "#         ts = df2[col].loc[zc]\n",
    "\n",
    "#     ts.plot(label=str(zc), ax=ax)\n",
    "\n",
    "#     #Max_ = ts.loc[‘2004’:’2010’].idxmax()\n",
    "#     Crash = '01-2009'\n",
    "#     #Min_ = tx.loc[crsh:].idxmin()\n",
    "\n",
    "#     #Ax.axvline(max_, label='Max Price', color ='green', ls=':')\n",
    "#     ax.axvline(crash, label='Housing Index Drops', color='red', ls=':')\n",
    "#     #Ax.axvline(min_, label='Min Price Post-Crash', color='black', ls=':')\n",
    "\n",
    "#     ax.legend()\n",
    "\n",
    "#     return fig,ax\n",
    "\n",
    "# fig, ax = plot_ts(df2, zipcodes=[21201,21207,1267,60625, 90025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ddd9240941e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#********************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexSlice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2014-01-01'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# #********************************************\n",
    "# data = df2.loc[pd.IndexSlice[:,'2014-01-01':],:].copy()\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********************************************\n",
    "# data.reset_index(inplace=True,level=0,drop=True)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********************************************\n",
    "# #Ts=df[‘MeanValue’].loc[‘2010:]\n",
    "# ts =data.loc[df['RegionName']==1267][\"MeanValue\".rename(1267)\n",
    "# ts.head()\n",
    "# #Ts=ts[‘MeanValue’]\n",
    "# #TS=TS.rename[‘1267’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********************************************\n",
    "# ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********************************************\n",
    "# ts = ts.resample('MS').asfreq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********************************************\n",
    "# ts.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********************************************\n",
    "# ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********************************************\n",
    "# def plot_acf_pacf(ta, figsize=(10,6),lags=15):\n",
    "    \n",
    "#     fig,ax = plt.subplots(nrows=2,figsize)\n",
    "#     plot_acf(ts,ax=ax[0],lags=lags)\n",
    "#     plot_pacf(ts,ax=ax[1],lags=lags)\n",
    "#     plt_tight_layout()\n",
    "\n",
    "#     for a in ax:\n",
    "#         a.xaxis.set_major_locator(mpl.ticker.MaxNLocator(min_n_ticks=lags, integer=True))\n",
    "#         a.xaxis.grid()\n",
    "\n",
    "# plot_acf_pacf(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the time series\n",
    "# melted_df_chicago.plot(figsize=(12,6), linewidth=2, fontsize=12)\n",
    "# plt.xlabel('Year', fontsize=20)\n",
    "# plt.ylabel('Value', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'melted_df_chicago' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-00fa95dccbef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Difference the time series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmelted_df_chicago\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'melted_df_chicago' is not defined"
     ]
    }
   ],
   "source": [
    "# Difference the time series\n",
    "data_diff = melted_df_chicago.diff().dropna()\n",
    "data_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference the time series\n",
    "data_diff = melted_df_chicago.diff().dropna()\n",
    "data_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use statsmodels to plot the ACF and PACF of this differenced time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ACF\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "plot_acf(data_diff,ax=ax, lags=8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PACF\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "plot_pacf(data_diff,ax=ax, lags=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = seasonal_decompose(ts)\n",
    "decomp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = seasonal_decompose(ts)\n",
    "ts_seas = decomp.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ts_seas.plot()\n",
    "fig = ax.get_figure()\n",
    "fig.set_size_inches(10,4)\n",
    "\n",
    "#get min and max idx\n",
    "min_ = ts_seas.idxmin()\n",
    "max_ = ts_seas.idxmax()\n",
    "min_2 = ts_seas.loc[max_:].idxmin()\n",
    "\n",
    "ax.axvline(min_, label=min, c='orange')\n",
    "ax.axvline(max_, c='orange', ls=':')\n",
    "ax.axvline(min_2, c='orange')\n",
    "\n",
    "period = min_2 - min_\n",
    "ax.set_title(f'Season Length = {period}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: ARIMA Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the ACF and PACF, fit an ARMA model with the right orders for AR and MA. Feel free to try different models and compare AIC and BIC values, as well as significance values for the parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ARMA\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Fit an ARMA(1,0) model\n",
    "mod_arma = ARMA(data_diff, order=(1,0))\n",
    "res_arma = mod_arma.fit()\n",
    "\n",
    "# Print out summary information on the fit\n",
    "print(res_arma.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an ARMA(2,1) model\n",
    "mod_arma = ARMA(data_diff, order=(2,1))\n",
    "res_arma = mod_arma.fit()\n",
    "\n",
    "# Print out summary information on the fit\n",
    "print(res_arma.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an ARMA(2,2) model\n",
    "mod_arma = ARMA(data_diff, order=(2,2))\n",
    "res_arma = mod_arma.fit()\n",
    "\n",
    "# Print out summary information on the fit\n",
    "print(res_arma.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection for the ARIMA Time Series Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step towards fitting an ARIMA model is to find the values of ARIMA(p,d,q)(P,D,Q)s that produce the desired output. Selection of these parameters requires domain expertise and time. We shall first generate small ranges of these parameters and use a \"grid search\" to iteratively explore different combinations of parameters. For each combination of parameters, we fit a new seasonal ARIMA model with the SARIMAX() function from the statsmodels library and assess its overall quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "p = d = q = range(0, 2)\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "pdqs = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC (Akaike Information Criterion) as Regularization Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Akaike information criterion (AIC) is an estimator of the relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection.\n",
    "\n",
    "A model that fits the data very well while using lots of features will be assigned a larger AIC score than a model that uses fewer features to achieve the same goodness-of-fit. Therefore, we are interested in finding the model that yields the lowest AIC value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a grid with pdq and seasonal pdq parameters calculated above and get the best AIC value\n",
    "ans = []\n",
    "for comb in pdq:\n",
    "    for combs in pdqs:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(CO2,\n",
    "                                            order=comb,\n",
    "                                            seasonal_order=combs,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            output = mod.fit()\n",
    "            ans.append([comb, combs, output.aic])\n",
    "            print('ARIMA {} x {}12 : AIC Calculated ={}'.format(comb, combs, output.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug the optimal parameter values into a new SARIMAX model\n",
    "ARIMA_MODEL = sm.tsa.statespace.SARIMAX(data_diff, \n",
    "                                        order=(1, 1, 1), \n",
    "                                        seasonal_order=(1, 1, 1, 12), \n",
    "                                        enforce_stationarity=False, \n",
    "                                        enforce_invertibility=False)\n",
    "\n",
    "# Fit the model and print results\n",
    "output = ARIMA_MODEL.fit()\n",
    "\n",
    "print(output.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model returns a lot of information, but we'll focus only on the table of coefficients. The coef column above shows the importance of each feature and how each one impacts the time series patterns. The $P>|z|$ provides the significance of each feature weight.\n",
    "\n",
    "For our time-series, we see that each weight has a p-value lower or close to 0.05, so it is reasonable to retain all of them in our model.\n",
    "\n",
    "Next, we shall run model diagnostics to ensure that none of the assumptions made by the model have been violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call plot_diagnostics() on the results calculated above \n",
    "output.plot_diagnostics(figsize=(15, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose here is to ensure that residuals remain uncorrelated, normally distributed having zero mean. In the absence of these assumptions, we can not move forward and need further tweaking of the model.\n",
    "\n",
    "Let's check for these assumptions from diagnostics plots.\n",
    "\n",
    "In the top right plot, we see that the red KDE line follows closely with the N(0,1) line (where N(0,1)) is the standard notation for a normal distribution with mean 0 and standard deviation of 1). This is a good indication that the residuals are normally distributed.\n",
    "\n",
    "The qq-plot on the bottom left shows that the ordered distribution of residuals (blue dots) follows the linear trend of the samples taken from a standard normal distribution with N(0, 1). Again, this is a strong indication that the residuals are normally distributed.\n",
    "\n",
    "The residuals over time (top left plot) don't display any obvious seasonality and appear to be white noise. This is confirmed by the autocorrelation (i.e. correlogram) plot on the bottom right, which shows that the time series residuals have low correlation with lagged versions of itself.\n",
    "\n",
    "These observations lead us to conclude that our model has no correlations and provides a satisfactory fit to help forecast future values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below:\n",
    "\n",
    "Get the predictions from 1st January 1998 till 2002 (end of time series)\n",
    "\n",
    "Get the confidence intervals for all predictions\n",
    "\n",
    "For get_predictions(), set the dynamic parameter to False to ensure that we produce one-step ahead forecasts, meaning that forecasts at each point are generated using the full history up to that point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-903f14f1d2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpl' is not defined"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize']=[12,5]\n",
    "ts.plot()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    ax = ts.diff(i).plot(label=i) \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "q_range = range(0.10)\n",
    "d_range = range(1,3)\n",
    "m_range=(0,6,12)\n",
    "\n",
    "pdq = list(itertools.product(p_range, d_range, q_range))\n",
    "PDQM = list(itertools.product(p_range,d_range,q_range,m_range))\n",
    "PDQM[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pdq_pdqm(p_range=range(0,10), q_range = range(0,10), \n",
    "    d_range=range(1,3), make_seasonal=True, m_values=(0,6,12)):\n",
    "\n",
    "    import itertools\n",
    "    ps = range(p_range[0],p_range[1])\n",
    "    ds = range(d_range[0],d_range[1])\n",
    "    qs = range(q_range[0],q_range[1])\n",
    "\n",
    "    params = {}\n",
    "    params['pdq'] = list(itertools.product(ps,ds,qs))\n",
    "\n",
    "    return params\n",
    "\n",
    "    params = make_pdq_pdqm()\n",
    "    params\n",
    "    params.keys()\n",
    "    if make_seasonal:\n",
    "        params['PDQM'] = list(itertools.product(ps,ds,qs,m_values))\n",
    "    return params\n",
    "\n",
    "#Pdq = list(itertools.product(p_range, d_range, q_range))\n",
    "#PDQM = list(itertools.product(p_range, d_range, q_range, m_range))\n",
    "#PDQM(:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split_index(ts, TEST_SIZE=0.1, min_Test_ts=2):\n",
    "    import math\n",
    "    idx_split – math.floor(len(ts.index)*(1-TEST_SIZE))\n",
    "\n",
    "    num_test_ts=len(ts.iloc[idx_split:])\n",
    "    if num_test_ts < min_test_ts:\n",
    "        print(f'[!] Warning: unsing TEST_SIZE={TEST_SIZE} produced {num_test_ts} test timestamps')\n",
    "        print(\" - Overriding TEST_SIZE and using min_test_ts instead.\")\n",
    "        idx_split = len(ts)-min_test_ts\n",
    "    return idx_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_ts(ts,test_size=0.2, min_test_ts=2):\n",
    "    idx_split = get_train_test_split_index(ts, TEST_SIZE=test_size, min_test_ts=min_test_ts)\n",
    "\n",
    "    ts_train = ts.iloc[:idx_split]\n",
    "    ts_Test = ts.iloc[idx_split:[\n",
    "\n",
    "    return ts_train, ts_test\n",
    "\n",
    "ts_train, ts_test = train_test_split_ts(ts)\n",
    "\n",
    "len(ts_train), len(ts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "def grid_search_sarimax(ts_train,pdq=None,pdqm=None,order_dict=None,verbose=False):\n",
    "\n",
    "    from tdqm import trange\n",
    "\n",
    "    if (pdq is None) & (order_dict is not None):\n",
    "        pdq= order_dict[‘pdq’]\n",
    "    if (pdqm is None) & (order_dict is not None):\n",
    "        pdqm= order_dict['PDQM']\n",
    "\n",
    "    import tqdm\n",
    "    from tqdm import trange\n",
    "\n",
    "    start, start_str = get+now(return_dt=True, return_str=True)\n",
    "    print(f'[i] STARTING GRID SEARCH @ {start_str}:')\n",
    "\n",
    "    res = [['pdq', 'PDQM', 'IAC']]\n",
    "        \n",
    "    for i in trange((len(pdq))):\n",
    "        comb = pdq[i]\n",
    "    for combs in pdqm:\n",
    "        try:\n",
    "        model = SARIMAX(ts_train, order=comb, seasonal_order=combs, enforce_stationarity=False, enforce_invertibility=False)\n",
    "\n",
    "        output = model.fit()\n",
    "        res.append([comb,combs,output.sic])\n",
    "    except:\n",
    "    if verbose:\n",
    "        print(f'[!] Error running ({comb})({combs})')\n",
    "    continue\n",
    "\n",
    "    end, end_str = get_now(return_det=True, return_str=True)\n",
    "    elapsed = end-start\n",
    "    print(f'[i] GRID SEARCH FINISHED AT {end_str}')\n",
    "    print(f'\\totTotal Time: {elapsed} sec')\n",
    "\n",
    "    try:\n",
    "        df_res = fs.list2df(res)\n",
    "        return df_res\n",
    "        except:\n",
    "        print(‘Error converting to df. Retuning as list.’)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = grid_search_sarimax(ts_train,order_dict=params)#pdq,pdqm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Interpreting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARMA(1,0), ARMA(2,2) and ARMA(2,1) all seem to have decent fits with significant parameters. \n",
    "Depending on whether you pick AIC or BIC as a model selection criterion, \n",
    "your result may vary. In this situation, you'd generally go for a model with fewer parameters, \n",
    "so ARMA(1,0) seems fine. Note that we have a relatively short time series, \n",
    "which can lead to a more difficult model selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions starting from 05-01-1996 and calculate confidence intervals\n",
    "pred = output.get_prediction(start=pd.to_datetime('1996-05-01'), dynamic=False)\n",
    "pred_conf = pred.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now plot the real and forecasted values of the CO2 time series to assess how well we did:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Real Vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot real vs predicted values along with confidence interval\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "# Plot observed values\n",
    "ax = data_diff['1990':].plot(label='observed')\n",
    "\n",
    "# Plot predicted values\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=0.9)\n",
    "\n",
    "# Plot the range for confidence intervals\n",
    "ax.fill_between(pred_conf.index,\n",
    "                pred_conf.iloc[:, 0],\n",
    "                pred_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "# Set axes labels\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecasts align with the true values as seen above, with overall increase trend. We shall also check for the accuracy of our forecasts using MSE (Mean Squared Error). This will provide us with the average error of our forecasts. For each predicted value, we compute its distance to the true value and square the result. The results need to be squared so that positive/negative differences do not cancel each other out when we compute the overall mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the real and predicted values\n",
    "chicago_forecasted = pred.predicted_mean\n",
    "chicago_truth = data_diff['1996-05-01':]\n",
    "\n",
    "# Compute the mean square error\n",
    "mse = ((chicago_forecasted - chicago_truth) ** 2).mean()\n",
    "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE of our one-step ahead forecasts yields a value of 0.07, which is very low. An MSE this close to 0 indicates that the estimator is predicting observations of the parameter with perfect accuracy, which would be an ideal scenario but it is not typically possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can achieve a deeper insight into model's predictive power using dynamic forecasts. In this case, we only use information from the time series up to a certain point, and after that, forecasts are generated using values from previous forecasted time points.\n",
    "\n",
    "Repeat above calculation for predictions post 1998. Use Dynamic forecasting by setting dynamic to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-e8e912c40f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get dynamic predictions with confidence intervals as above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_dynamic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1996-05-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_dynamic_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_dynamic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "# Get dynamic predictions with confidence intervals as above \n",
    "pred_dynamic = output.get_prediction(start=pd.to_datetime('1996-05-01'), dynamic=True, full_results=True)\n",
    "pred_dynamic_conf = pred_dynamic.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the observed and forecasted values of the time series, we see that the overall forecasts are accurate even when using dynamic forecasts. All forecasted values (red line) match pretty closely to the ground truth (blue line), and are well within the confidence intervals of our forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_diff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d709226eb2d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the dynamic forecast with confidence intervals.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_diff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1990'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'observed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred_dynamic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Dynamic Forecast'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_diff' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the dynamic forecast with confidence intervals.\n",
    "\n",
    "ax = data_diff['1990':].plot(label='observed', figsize=(20, 15))\n",
    "pred_dynamic.predicted_mean.plot(label='Dynamic Forecast', ax=ax)\n",
    "\n",
    "ax.fill_between(pred_dynamic_conf.index,\n",
    "                pred_dynamic_conf.iloc[:, 0],\n",
    "                pred_dynamic_conf.iloc[:, 1], color='g', alpha=.3)\n",
    "\n",
    "ax.fill_betweenx(ax.get_ylim(), pd.to_datetime('1996-05-01'), chicago_forecasted.index[-1], alpha=.1, zorder=-1)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Value')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we quantify the predictive performance of our forecasts by computing the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the predicted and true values of our time series\n",
    "chicago_forecasted = pred_dynamic.predicted_mean\n",
    "chicago_truth = data_diff['1996-05-01':]\n",
    "\n",
    "# Compute the mean square error\n",
    "mse = ((chicago_forecasted - chicago_truth) ** 2).mean()\n",
    "print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted values obtained from the dynamic forecasts yield an MSE of 1.01. This is slightly higher than the one-step ahead, which is to be expected given that we are relying on less historical data from the time series.\n",
    "\n",
    "Both the one-step ahead and dynamic forecasts confirm that this time series model is valid. However, much of the interest around time series forecasting is the ability to forecast future values way ahead in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing and Visualizing Forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now describe how to leverage our seasonal ARIMA time series model to forecast future values. The .get_forecast() method of our time series output can compute forecasted values for a specified number of steps ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecast 500 steps ahead in future\n",
    "prediction = output.get_forecast(steps=500)\n",
    "\n",
    "# Get confidence intervals of forecasts\n",
    "pred_conf = prediction.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the output of this code to plot the time series and forecasts of its future values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot future predictions with confidence intervals\n",
    "ax = data_diff.plot(label='observed', figsize=(20, 15))\n",
    "prediction.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "ax.fill_between(pred_conf.index,\n",
    "                pred_conf.iloc[:, 0],\n",
    "                pred_conf.iloc[:, 1], color='k', alpha=0.25)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Value')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we forecast further out into the future, it is natural for us to become less confident in our values. This is reflected by the confidence intervals generated by our model, which grow larger as we move further out into the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
